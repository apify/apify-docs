---
title: Kestra integration
description: Connect Apify with Kestra to orchestrate workflows — run flows, extract structured data, and react to Actor or task events in real time.
sidebar_label: Kestra
sidebar_position: 7
slug: /integrations/kestra
---

**Connect Apify with Kestra to orchestrate workflows — run flows, extract structured data, and react to Actor or task events in real time.**

---

[Kestra](https://kestra.io/) is an open-source, event-driven orchestration platform that unifies workflows for all engineers.
With the [Apify plugin for Kestra](https://github.com/kestra-io/plugin-kestra), you can seamlessly connect Apify Actors and storage to your workflows.
Run scrapers, extract structured data — all defined declaratively in YAML and orchestrated directly from the UI.
In this guide, you'll learn how to set up and incorporate authentication into a Kestra flows.

## Prerequisites

Before you begin, make sure you have:

- An [Apify account](https://console.apify.com/)
- A [Kestra instance](https://kestra.io/docs/getting-started/quickstart) (self‑hosted or cloud)

Once installed, the next step is authentication.

## Authentication

The Apify plugin for Kestra uses **API Key authentication** to securely connect with your Apify account.
This method works for both self-hosted and cloud instances.

You can store and manage your API key directly in [Kestra Secrets](https://kestra.io/docs/concepts/secret)
in the UI or through environment variables, ensuring credentials stay secure and flows remain declarative. In the open-source version, Secrets can be managed using base64-encoded environment variables.

For open-source deployments, you can also use [Kestra’s KV Store](https://kestra.io/docs/concepts/kv-store)
to persist and share API keys (or other values) across executions and workflows.

With authentication configured, you can now define flows that integrate the Apify plugin — orchestrating scrapers, data extraction, and event-driven tasks directly from Kestra.

## Create a flow with the Apify Plugin

Start by building a basic flow in Kestra,
then add any Apify Task to handle jobs like running Actors
or fetching data.

1. Create a new flow in Kestra.
1. Select **Add Node**, search for **Apify**, and select it.
1. Choose the desired **Resource** and **Operation**.
1. In the node's **Credentials** dropdown, choose the Apify credential you configured earlier. If you haven't configured any credentials, you can do so in this step. The process will be the same.
1. You can now use Apify node as a trigger or action in your workflow.

## Use Apify Tasks as an action

Tasks allow you to perform operations like running an Actor within a workflow.

1. Create a new flow.
1. Inside the **Flow code** tab change the hello task's type to be **io.kestra.plugin.apify.actor.Run**.
1. Change the task's id to be **run_apify_actor**
1. Remove the message property.
1. Configure the **run_apify_actor** task by adding your required values for the properties listed below:
    - **actorId**: Actor ID or a tilde-separated owner's username and Actor name.
    - **apiToken**: A reference to the secret value you set up earlier. For example "\{\{secret(namespace=flow.namespace, key='APIFY_API_KEY')\}\}"
1. Add a new task below the **run_apify_actor** with an ID of **get_dataset** and a type of **io.kestra.plugin.apify.dataset.Get**.:
1. Configure the **get_dataset** to fetch the dataset generated by the **run_apify_actor** task by configuring the following values:
    - **datasetId**: The ID of the dataset to fetch. You can use the value from the previous task using the following syntax: "\{\{secret(namespace=flow.namespace, key='APIFY_API_KEY')\}\}"
    - **input**: Input for the Actor run. The input is optional and can be used to pass data to the Actor. For our example we will add 'hashtags: ["fyp"]'
    - **maxItems**: The maximum number of items to fetch from the dataset. For our example we will set this to 5.
1. Now add the final task to log the output of the dataset. Add a new task below the **log_output** with an ID of **log_output** and a type of **io.kestra.plugin.core.log.Log**.
1. Configure the **log_output** task to log the output of the dataset by configuring the following values:
    - **message**: The message to log. You can use the value from the previous task using the following syntax: '\{\{outputs.get_dataset.dataset\}\}'
1. Now save and run your flow.

Your completed template should match the template below.
```yaml
id: get_last_actor_run_and_get_dataset
namespace: company.team

tasks:
    - id: run_actor
      type: io.kestra.plugin.apify.actor.Run
      actorId: GdWCkxBtKWOsKjdch
      maxItems: 5
      input:
          hashtags: ["fyp"]
      apiToken: "{{secret(namespace=flow.namespace, key='APIFY_API_KEY')}}"
    - id: log_get_last_run_results
      type: io.kestra.plugin.core.log.Log
      message: '{{outputs.run_actor}}'
    - id: get_data_set_raw
      type: io.kestra.plugin.apify.dataset.Get
      datasetId: '{{outputs.run_actor.defaultDatasetId}}'
      apiToken: "{{secret(namespace=flow.namespace, key='APIFY_API_KEY')}}"
    - id: log_get_data_set_raw_results
      type: io.kestra.plugin.core.log.Log
      message: '{{outputs.get_data_set_raw}}'
```

## Resources

- [Kestra Apify Plugin](https://kestra.io/plugins/plugin-apify)
- [Apify API Documentation](https://docs.apify.com)
- [Kestra Documentation](https://kestra.io/docs)

## Troubleshooting

If you encounter issues, start by double-checking basics.

- **Authentication errors**: Verify your API token in [Secrets](https://kestra.io/docs/concepts/secret).
- **Operation failures**: Check input parameters, JSON syntax, and resource IDs in your Apify account.

Feel free to explore other resources and contribute to the integration on [GitHub](https://github.com/kestra-io/plugin-apify).
